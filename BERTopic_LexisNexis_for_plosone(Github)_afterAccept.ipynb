{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"9VE2b7WvuyEV"},"outputs":[],"source":["from umap import UMAP\n","from hdbscan import HDBSCAN\n","from sentence_transformers import SentenceTransformer\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","from bertopic import BERTopic\n","from bertopic.vectorizers import ClassTfidfTransformer\n","\n","from octis.dataset.dataset import Dataset\n","from octis.models.model import AbstractModel\n","from octis.evaluation_metrics.diversity_metrics import TopicDiversity\n","from octis.evaluation_metrics.coherence_metrics import Coherence\n","from octis.models.CTM import CTM\n","\n","from contextualized_topic_models.models.ctm import CombinedTM\n","from contextualized_topic_models.utils.data_preparation import TopicModelDataPreparation\n","from contextualized_topic_models.utils.data_preparation import bert_embeddings_from_file\n","from contextualized_topic_models.evaluation.measures import CoherenceCV\n","\n","from gensim import corpora\n","from gensim.models import LdaModel\n","import gensim.downloader as api\n","from gensim.models.coherencemodel import CoherenceModel\n","from gensim import corpora\n","\n","import os\n","import numpy as np\n","import pandas as pd\n","\n","from skopt.space.space import Real, Categorical, Integer\n","\n","import warnings\n","\n","warnings.filterwarnings(\"ignore\")\n","warnings.filterwarnings(\"ignore\", message=\" `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above. and should_run_async(code)\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3nEhXJYaGQ1c"},"outputs":[],"source":["df = pd.read_csv('Load your data!')\n","df = df.drop_duplicates()\n","df = df.reset_index(drop=True)\n","df.head(3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1dHuQXvWbU-6"},"outputs":[],"source":["# Diversity\n","import re\n","\n","doc_list = []\n","\n","for idx, row in df.iterrows():\n","    document = str(row['Article'])\n","    doc_list.append(document)\n","\n","print(len(doc_list))\n","\n","newdocs = [re.sub(' +',' ', doc.strip().replace('\\n', ' ').replace('\\r', ' ').replace('\\t', ' ').replace('\"', '\\'').replace('\\x0c', '').replace('\\x1c', '')) for doc in doc_list]\n","\n","# write the two files needed to create an OCTIS dataset\n","with open(\"corpus.tsv\", \"w\") as f :\n","    f.write(\"\\n\".join(map(str, newdocs)))\n","f.close()\n","words = []\n","for line in newdocs :\n","  words.extend(line.split())\n","\n","with open(\"vocabulary.txt\", \"w\") as f :\n","    f.write(\"\\n\".join(map(str, words)))\n","f.close()"]},{"cell_type":"markdown","metadata":{"id":"FbheCurw6zhW"},"source":["# Coherence & Diversity Calculation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a9wJ4LKrZrdi"},"outputs":[],"source":["os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n","topic_range = range(2, 11)\n","\n","tokenized_documents = [doc.split() for doc in df['Article']]\n","dictionary = corpora.Dictionary(tokenized_documents)\n","corpus = [dictionary.doc2bow(doc) for doc in tokenized_documents]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PvfLz39WzowT"},"outputs":[],"source":["# LDA coherence, diversity\n","\n","coherence_values_lda = []\n","diversity_values_lda = []\n","\n","for num_topics in topic_range:\n","    #Load LDA model\n","\n","    lda_topics = []\n","    for topic_id, topic_words in lda_model.print_topics():\n","        #Preprocessing on a word-by-word basis\n","\n","    #Save the topics\n","\n","    #Calculate diversity and save\n","\n","    #Calcuate coherence and save"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZA0lojCXzuLn"},"outputs":[],"source":["# nmf coherence, diversity\n","from gensim.models import Nmf\n","\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n","\n","coherence_values_nmf = []\n","diversity_values_nmf = []\n","\n","for num_topics in topic_range:\n","    #Load NMF model\n","\n","    nmf_topics = []\n","    for topic_id, topic_words in nmf_model.print_topics():\n","         #Preprocessing on a word-by-word basis\n","\n","    #Save the topics\n","\n","    #Calculate diversity and save\n","\n","    #Calcuate coherence and save"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zeZPAvv5T7rf"},"outputs":[],"source":["# CTM coherence\n","topic_range = range(2,11)\n","coherence_values_ctm = []\n","diversity_values_ctm = []\n","\n","qt = TopicModelDataPreparation(\"all-mpnet-base-v2\")\n","\n","for num_topics in topic_range:\n","    #Load CTM model and Train!\n","\n","    #Save the topics\n","\n","    #Calcuate coherence and save"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JsuYXdyk2SkU"},"outputs":[],"source":["# CTM diversity\n","training_dataset = qt.fit(text_for_contextual=df['Article'], text_for_bow=df['tokenized_text'])\n","\n","diversity_values_ctm = []\n","\n","for num_topics in topic_range:\n","    #Load CTM model and Train!\n","\n","    #Save the topics\n","\n","    #Calculate diversity and save"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5fPsH5Yn4Iip"},"outputs":[],"source":["# BERTopic\n","embedding_model = SentenceTransformer(\"multi-qa-miniLM-L6-cos-v1\")\n","umap_model = UMAP(n_neighbors=30, n_components=3, min_dist=0.2, metric='cosine')\n","hdbscan_model = HDBSCAN(min_cluster_size=16, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n","vectorizer_model = CountVectorizer(stop_words=\"english\")\n","ctfidf_model = ClassTfidfTransformer()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bZbfg6AHi2QU"},"outputs":[],"source":["# BERTopic coherence, diversity\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n","\n","coherence_values_bertopic = []\n","diversity_values_bertopic = []\n","\n","for num_topics in topic_range:\n","\n","    #Train BERTopic model and get topics\n","\n","    bertopic_topics = [\n","        [topicwords[0] for topicwords in topic_model.get_topic(i)[:]]\n","        for i in range(len(result_get_topic)-1)]\n","\n","    result = dict()\n","    result['topics'] = bertopic_topics\n","\n","    documents = pd.DataFrame({\"Document\": df['tokenized_text'],\n","                          \"ID\": range(len(df['tokenized_text'])),\n","                          \"Topic\": topics})\n","    documents_per_topic = documents.groupby(['Topic'], as_index=False).agg({'Document': ' '.join})\n","    cleaned_docs = topic_model._preprocess_text(documents_per_topic.Document.values)\n","\n","    vectorizer = topic_model.vectorizer_model\n","    analyzer = vectorizer.build_analyzer()\n","\n","    words = vectorizer.get_feature_names_out()\n","\n","    topic_words = [[words for words, _ in topic_model.get_topic(topic)]\n","                for topic in range(len(set(topics))-1)]\n","\n","    #Calculate Coherence and Diversity"]},{"cell_type":"markdown","metadata":{"id":"-ET896FuWo7m"},"source":["# Topic Modeling Results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jn4lGg5wYj54"},"outputs":[],"source":["topic_model = BERTopic(embedding_model=embedding_model,\n","                       umap_model=umap_model,\n","                       hdbscan_model=hdbscan_model,\n","                       vectorizer_model=vectorizer_model,\n","                       ctfidf_model=ctfidf_model,\n","                       top_n_words = 12,\n","                       nr_topics=8)\n","topics, probs = topic_model.fit_transform(df['tokenized_text'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YI5Ttn4HYy74"},"outputs":[],"source":["result_get_topic = topic_model.get_topic_info()\n","result_get_topic"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jakA14tmY4mf"},"outputs":[],"source":["topic_weight = topic_model.get_topics()\n","topic_weight"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QzCEk7AoY5fX"},"outputs":[],"source":["topic_weight = pd.DataFrame.from_dict(topic_weight, orient='index')\n","topic_weight"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sQ9qfvnhY9ie"},"outputs":[],"source":["topic_model.visualize_barchart(top_n_topics=25)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JItYecmEZAQg"},"outputs":[],"source":["topic_model.visualize_heatmap(width=800, height=600)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9g5ChC_1itoQ"},"outputs":[],"source":["topic_model.visualize_topics()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":0}